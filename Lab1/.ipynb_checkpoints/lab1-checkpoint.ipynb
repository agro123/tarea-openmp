{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to OpenMP\n",
    "\n",
    "The objective of this lab is to get familiar with the basic concepts behind OpenMP. Some of these concepts are shared with other programming models, and are important to understand how systems are programmed in parallel. These concepts are introduced directly using OpenMP syntax. It is not expected for the reader to know OpenMP, but they should be familiar with C-like syntax.\n",
    "\n",
    "This tutorial is expected to run in a unix-like environment.\n",
    "\n",
    "## Table of content:\n",
    "\n",
    "* Thread and multithread\n",
    "    * First parallel program\n",
    "    * Thinking in parallel\n",
    "    * Exercise 1\n",
    "* Memory: Shared, private, distributed\n",
    "    * Atomic operations\n",
    "    * Private vs Firstprivate\n",
    "    * Reductions\n",
    "    * Lastprivate\n",
    "    * Exercise 2\n",
    "* OpenMP Syntax\n",
    "* Function outlining, implementation and runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread and multithreads\n",
    "\n",
    "Simply speaking, a thread is a worker that execute instructions. Current CPU architectures are mostly multi threaded, where each worker is independent to each other. \n",
    "\n",
    "Let's see how many cores are in our current system using `lscpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:            x86_64\n",
      "  CPU op-mode(s):        32-bit, 64-bit\n",
      "  Address sizes:         48 bits physical, 48 bits virtual\n",
      "  Byte Order:            Little Endian\n",
      "CPU(s):                  12\n",
      "  On-line CPU(s) list:   0-11\n",
      "Vendor ID:               AuthenticAMD\n",
      "  Model name:            AMD Ryzen 5 5600G with Radeon Graphics\n",
      "    CPU family:          25\n",
      "    Model:               80\n",
      "    Thread(s) per core:  2\n",
      "    Core(s) per socket:  6\n",
      "    Socket(s):           1\n",
      "    Stepping:            0\n",
      "    CPU max MHz:         4464.0000\n",
      "    CPU min MHz:         400.0000\n",
      "    BogoMIPS:            7799.62\n",
      "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc\n",
      "                         a cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall n\n",
      "                         x mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_go\n",
      "                         od nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl p\n",
      "                         ni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2api\n",
      "                         c movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_le\n",
      "                         gacy svm extapic cr8_legacy abm sse4a misalignsse 3dnow\n",
      "                         prefetch osvw ibs skinit wdt tce topoext perfctr_core p\n",
      "                         erfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw\n",
      "                         _pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 \n",
      "                         avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap c\n",
      "                         lflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cq\n",
      "                         m_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local user_sh\n",
      "                         stk clzero irperf xsaveerptr rdpru wbnoinvd cppc arat n\n",
      "                         pt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushby\n",
      "                         asid decodeassists pausefilter pfthreshold avic v_vmsav\n",
      "                         e_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqd\n",
      "                         q rdpid overflow_recov succor smca fsrm debug_swap\n",
      "Virtualization features: \n",
      "  Virtualization:        AMD-V\n",
      "Caches (sum of all):     \n",
      "  L1d:                   192 KiB (6 instances)\n",
      "  L1i:                   192 KiB (6 instances)\n",
      "  L2:                    3 MiB (6 instances)\n",
      "  L3:                    16 MiB (1 instance)\n",
      "NUMA:                    \n",
      "  NUMA node(s):          1\n",
      "  NUMA node0 CPU(s):     0-11\n",
      "Vulnerabilities:         \n",
      "  Gather data sampling:  Not affected\n",
      "  Itlb multihit:         Not affected\n",
      "  L1tf:                  Not affected\n",
      "  Mds:                   Not affected\n",
      "  Meltdown:              Not affected\n",
      "  Mmio stale data:       Not affected\n",
      "  Retbleed:              Not affected\n",
      "  Spec rstack overflow:  Vulnerable: Safe RET, no microcode\n",
      "  Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl\n",
      "  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer\n",
      "                          sanitization\n",
      "  Spectre v2:            Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIB\n",
      "                         P always-on, RSB filling, PBRSB-eIBRS Not affected\n",
      "  Srbds:                 Not affected\n",
      "  Tsx async abort:       Not affected\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above you can find the number of CPUs (e.g. 8) and the number of Threads per CPU (e.g. 2). Each Thread is capable of independently handle a different stream of instructions. However, **software often creates more threads than available in the hardware system**. \n",
    "\n",
    "You can ignore the syntax in the following command, but its output will show the number of threads running within all processes in the system (or at least those that your user can obtain information about). __Most likely you will find that the number of *software* threads is much larger than the number of *hardware* threads. This is because the operating system uses a scheduling scheme to execute all the threads concurrently__. \n",
    "\n",
    "The focus of this lab is not to learn about OS threads, but it is worth knowing that the number of *software* threads in a given program can be larger than the number of *hardware* threads running in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "!ps -eo nlwp | tail -n +2 | awk '{ num_threads += $1 } END { print num_threads }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create our first threaded program\n",
    "\n",
    "```C\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel num_threads(10)\n",
    "    {\n",
    "        printf(\"Hello from thread %d\\n\",omp_get_thread_num());\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's compile it\n",
    "!gcc -fopenmp C/parallel.c -o C/parallel.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from thread 3\n",
      "Hello from thread 10\n",
      "Hello from thread 1\n",
      "Hello from thread 0\n",
      "Hello from thread 9\n",
      "Hello from thread 7\n",
      "Hello from thread 2\n",
      "Hello from thread 6\n",
      "Hello from thread 11\n",
      "Hello from thread 5\n",
      "Hello from thread 8\n",
      "Hello from thread 4\n"
     ]
    }
   ],
   "source": [
    "# Now it is time to run it.\n",
    "!C/./parallel.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should immediately notice that (likely) the output of the above program is not in a given order. This is because all the threads are running concurrently, and, if the number of hardware threads is larger than 1, a set of them may be running in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it yourself\n",
    "\n",
    "Open the file [parallel.c](C/parallel.c) and play with different number of threads by changing the value inside the clause `num_threads()`, and re-running the above two commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking in parallel\n",
    "\n",
    "If you're experienced in sequential programming, __you're likely familiar with writing code for a single thread.  When thinking sequentially, the developer must primarly think of the instructions that are executed. Parallel programming adds an additional complexity to the development program. When writting programs, a developer must think of the following aspects of the code__:\n",
    "\n",
    "* **Workers creation**: How to create workers and how many to create\n",
    "* **Work assignment**: How to assign work to different workers\n",
    "* **Workers/resources communication and coordination**: How workers communicate and synchronize in order to coordinate their work.\n",
    "\n",
    "```\n",
    "Note: Different programming models exist that balance these three tasks. Here I am referring to the most popular programming models. Allow me to be simplistic here.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### The fork-join model - An example.\n",
    "\n",
    "OpenMP is mainly known for its *Fork-Join* model. Programs execute with an initial sequential thread until a directive (code anotation) is reached that initiates parallel threads (workers). Different directives are used to assign work to these threads. At the end of the parallel region, threads synchronize, forming again a single thread.\n",
    "\n",
    "For the above example. **worker creation** is achieved through the `#pragma omp parallel num_threads(10)` directive. It allows to create 10 threads. Each worker is associated with an identifier, obtained through the `omp_get_thread_num()` function call. **Work assignment** is achieved through the code in the region enclosed by the brackets `{...}`. All threads are executing the same set of instructions, in this case only `printf(\"hello from thread %d\\n\",...);`. Notice that having a different identifier allows for each thread to access different data, or follow different paths. Finally **worker synchronization and coordination** is relatively simple in this example, since there's not much communication between them. However, at the end of the parallel region, all workers must wait for each other to finish before continuing with the sequential code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Can you modify the code above to make the odd and even threads print something different?Go to exercise1.c and use the code region below to build and execute your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This thread is odd 1\n",
      "This thread is even 8\n",
      "This thread is even 0\n",
      "This thread is odd 9\n",
      "This thread is even 2\n",
      "This thread is odd 7\n",
      "This thread is even 6\n",
      "This thread is odd 3\n",
      "This thread is even 10\n",
      "This thread is odd 5\n",
      "This thread is even 4\n",
      "This thread is odd 11\n"
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp Exercises/exercise1.c -o Exercises/exercise1.exe && Exercises/./exercise1.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory: Shared vs Private\n",
    "\n",
    "When programming we often imagine memory as a single \"monolithic\" element. However, this is not the reality. __Current architectures feature a complex memory organization that includes registers, caches, multiple DRAM banks__, and even devices with a different memory space. When programming in parallel, such complex structures become more important for correctness and performance.\n",
    "\n",
    "__Multithreading programming often features shared memory, meaning that all threads have access to the same varibles__, located in the same memory address (I expect the reader to be familiar with pointers). __However, it is also possible for each thread to have private memory, even if the name of variables are the same__.\n",
    "\n",
    "Take for example the next program:\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i;\n",
    "    double share;\n",
    "    int Array[10];\n",
    "\n",
    "    printf(\"Address of i prior to the parallel region is: %lx\\n\",(unsigned long)&i);\n",
    "    printf(\"Address of shared prior to the parallel region is: %lx\\n\",(unsigned long)&share);\n",
    "    printf(\"Address of Array prior to the parallel region is: %lx\\n\",(unsigned long)Array);\n",
    "\n",
    "    #pragma omp parallel private(i, Array) shared(share)\n",
    "    {\n",
    "        printf(\"Address of i as seen by thread %d: %lx\\n\", omp_get_thread_num(), (unsigned long)&i);\n",
    "        printf(\"Address of Array as seen by thread %d: %lx\\n\", omp_get_thread_num(), (unsigned long)Array);\n",
    "        printf(\"Address of share as seen by thread %d: %lx\\n\", omp_get_thread_num(), (unsigned long)&share);\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/memory.c -o C/memory.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address of i prior to the parallel region is: 7ffed175defc\n",
      "Address of shared prior to the parallel region is: 7ffed175df00\n",
      "Address of Array prior to the parallel region is: 7ffed175df10\n",
      "Address of i as seen by thread 6: 7e6a7ff78d4c\n",
      "Address of Array as seen by thread 6: 7e6a7ff78d50\n",
      "Address of share as seen by thread 6: 7ffed175df00\n",
      "Address of i as seen by thread 5: 7e6a80779d4c\n",
      "Address of Array as seen by thread 5: 7e6a80779d50\n",
      "Address of share as seen by thread 5: 7ffed175df00\n",
      "Address of i as seen by thread 9: 7e6a7e775d4c\n",
      "Address of Array as seen by thread 9: 7e6a7e775d50\n",
      "Address of share as seen by thread 9: 7ffed175df00\n",
      "Address of i as seen by thread 7: 7e6a7f777d4c\n",
      "Address of Array as seen by thread 7: 7e6a7f777d50\n",
      "Address of share as seen by thread 7: 7ffed175df00\n",
      "Address of i as seen by thread 1: 7e6a8277dd4c\n",
      "Address of Array as seen by thread 1: 7e6a8277dd50\n",
      "Address of share as seen by thread 1: 7ffed175df00\n",
      "Address of i as seen by thread 2: 7e6a81f7cd4c\n",
      "Address of Array as seen by thread 2: 7e6a81f7cd50\n",
      "Address of share as seen by thread 2: 7ffed175df00\n",
      "Address of i as seen by thread 4: 7e6a80f7ad4c\n",
      "Address of Array as seen by thread 4: 7e6a80f7ad50\n",
      "Address of share as seen by thread 4: 7ffed175df00\n",
      "Address of i as seen by thread 11: 7e6a7d773d4c\n",
      "Address of Array as seen by thread 11: 7e6a7d773d50\n",
      "Address of share as seen by thread 11: 7ffed175df00\n",
      "Address of i as seen by thread 0: 7ffed175de6c\n",
      "Address of Array as seen by thread 0: 7ffed175de70\n",
      "Address of share as seen by thread 0: 7ffed175df00\n",
      "Address of i as seen by thread 10: 7e6a7df74d4c\n",
      "Address of Array as seen by thread 10: 7e6a7df74d50\n",
      "Address of share as seen by thread 10: 7ffed175df00\n",
      "Address of i as seen by thread 8: 7e6a7ef76d4c\n",
      "Address of Array as seen by thread 8: 7e6a7ef76d50\n",
      "Address of share as seen by thread 8: 7ffed175df00\n",
      "Address of i as seen by thread 3: 7e6a8177bd4c\n",
      "Address of Array as seen by thread 3: 7e6a8177bd50\n",
      "Address of share as seen by thread 3: 7ffed175df00\n"
     ]
    }
   ],
   "source": [
    "!C/./memory.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with this code going to [memory.c](C/memory.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Private memory allows for variables to be visible only by the current worker. Shared memory, allows variables to be visible from and modified by multiple workers (read and write)__. However, it is important to be careful. As previously mentioned, memory organization is complex, and requires additional coordination.\n",
    "\n",
    "Take for example the following program:\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i = 0;\n",
    "\n",
    "    #pragma omp parallel shared(i) num_threads(10000)\n",
    "    {\n",
    "        i++;\n",
    "    }\n",
    "    \n",
    "    printf(\"i = %d\\n\",i);\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/datarace.c -o C/datarace.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 990\n"
     ]
    }
   ],
   "source": [
    "!C/./datarace.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 10000 workers are created, and each is adding 1 to the value of i, the \"expected\" value would be 10000. If you're running this in a machine that has multiple threads, I expect you to see a number less than 10000. Moreover, multiple executions may lead to different results. This is what is known as a **data race**. It occurs because reading i, incrementing, and writting to i are three different instructions. Therefore, it is possible for two threads to write the same value of i, increment it and obtain the same value twice.\n",
    "\n",
    "For this reason, __shared memory requires additional coordination between workers__, such that reads and writes to the same region are perceived in the expected order.\n",
    "\n",
    "Notice that this is part of thinking about **workers/resource communication and coordination**. We are coordinating memory acesses and operations to variables, as they are shared across different workers.\n",
    "\n",
    "You can modify the above code going to [datarace.c](C/datarace.c)\n",
    "\n",
    "```\n",
    "Note: Data races are a difficult aspect of parallel programming. Multiple executions may lead to different results, but among the different results that can be obtained, it is still possible to obtain the \"expected\" result. Some data races are more difficult to debug than others, because they have a higher chance of choosing the \"expected\" result. Imagine that 1 out of a million executions of your code in a given hardware shows a datarace. Now imagine this program running the automatic pilot of an airplane...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atomic operations\n",
    "\n",
    "__Atomic operations allows different threads to perform different operations to the same memory location in a single instruction (or as if they were executed in a single instruction)__. In the example above, atomic operations would allow for read, increment and write to happen in a single instruction (or \"atomically\"). Thus, atomic operations can solve the datarace issue of the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "int main() {\n",
    "    int i = 0;\n",
    "\n",
    "    #pragma omp parallel shared(i) num_threads(10000)\n",
    "    {\n",
    "        #pragma omp atomic\n",
    "        i++;\n",
    "    }\n",
    "    \n",
    "    printf(\"i = %d\\n\",i);\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/atomic.c -o C/atomic.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1000\n"
     ]
    }
   ],
   "source": [
    "!C/./atomic.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [atomic.c](C/atomic.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private vs Firstprivate\n",
    "\n",
    "Privatization of variables means that a single variable name will have different memory locations. Privatization does not guarantee that the new address has the same value of the original address (i.e. the address before the parallel region). \n",
    "\n",
    "Take for example the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "int main() {\n",
    "    int i = 999;\n",
    "\n",
    "    printf(\"i is %d before parallel region\\n\",i);\n",
    "\n",
    "    #pragma omp parallel private(i) num_threads(10)\n",
    "    {\n",
    "        printf(\"Thread %d sees %d on memory %lx\\n\", omp_get_thread_num(), i, (unsigned long)&i);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/private.c -o C/private.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 999 before parallel region\n",
      "Thread 0 sees 0 on memory 7ffeeca405a4\n",
      "Thread 6 sees 0 on memory 7610bff3ad74\n",
      "Thread 5 sees 0 on memory 7610c073bd74\n",
      "Thread 8 sees 0 on memory 7610bef38d74\n",
      "Thread 3 sees 0 on memory 7610c173dd74\n",
      "Thread 1 sees 0 on memory 7610c273fd74\n",
      "Thread 2 sees 0 on memory 7610c1f3ed74\n",
      "Thread 4 sees 0 on memory 7610c0f3cd74\n",
      "Thread 7 sees 0 on memory 7610bf739d74\n",
      "Thread 9 sees 0 on memory 7610be737d74\n"
     ]
    }
   ],
   "source": [
    "!C/./private.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [private.c](C/private.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstprivate allows for each new address location to be initialized with the value prior to the parallel region. Take for example the following code.\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i[3] = {999,888,666};\n",
    "\n",
    "    printf(\"i is [%d,%d,%d] before parallel region\\n\",i[0],i[1],i[2]);\n",
    "\n",
    "    #pragma omp parallel firstprivate(i) num_threads(10)\n",
    "    {\n",
    "        printf(\"Thread %d sees [%d,%d,%d] on memory %lx\\n\", omp_get_thread_num(), i[0],i[1],i[2], (unsigned long)i);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/firstprivate.c -o C/firstprivate.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is [999,888,666] before parallel region\n",
      "Thread 6 sees [999,888,666] on memory 749aff73dd5c\n",
      "Thread 0 sees [999,888,666] on memory 7ffe6d0e25ac\n",
      "Thread 3 sees [999,888,666] on memory 749b00f40d5c\n",
      "Thread 2 sees [999,888,666] on memory 749b01741d5c\n",
      "Thread 7 sees [999,888,666] on memory 749afef3cd5c\n",
      "Thread 1 sees [999,888,666] on memory 749b01f42d5c\n",
      "Thread 8 sees [999,888,666] on memory 749afe73bd5c\n",
      "Thread 4 sees [999,888,666] on memory 749b0073fd5c\n",
      "Thread 9 sees [999,888,666] on memory 749afdf3ad5c\n",
      "Thread 5 sees [999,888,666] on memory 749afff3ed5c\n"
     ]
    }
   ],
   "source": [
    "!C/./firstprivate.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [firstprivate.c](C/firstprivate.c)\n",
    "\n",
    "Notice how each location for i is different on each thread, yet, all have the same expected value. __This also means that memory copies need to be performed in order to achieve this behavior. Hence, if your array is large, it may incur in additional overhead__.\n",
    "\n",
    "There are still a lot of good reasons to privatize variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions\n",
    "\n",
    "So far we have discussed what happens to variables when going from a sequential region to a parallel region. However, what happens to these multiple private memory locations when a parallel region is over? In principle, private variables are discarded (freed) at the end of a parallel region, hence, if their value are important, it is necessary to store them into a shared location that lives after the parallel region. Yet, it is often desireable to update the original memory location of the variable.\n",
    "\n",
    "But wait, all of these variables may have different values. How do I decide what's the final value to be used after the parallel region? Reductions are collective operations that aggregate the different values into a single value, by applying an operation. Ideally, this operation should be commutative, otherwise, how do I decide the order in which they are applied?\n",
    "\n",
    "```\n",
    "Note: Surprisingly enough OpenMP used to support the minus (-) operation for reductions. It wasn't until version 5.2 that they removed support for this operation. If thread 1 and thread 2 are reducing A, should it be At1 - At2 or At2 - At1?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take for example the following code:\n",
    "\n",
    "```C\n",
    "int main() {\n",
    "    int i = 99;\n",
    "\n",
    "    printf(\"Value if i prior to parallel region is %d\\n\",i);\n",
    "\n",
    "    // Private values are not transferred back\n",
    "    #pragma omp parallel private(i)\n",
    "    {\n",
    "        i=1000;\n",
    "    }\n",
    "    printf(\"Value if i after parallel region with private(i) is %d\\n\",i);\n",
    "\n",
    "    i = 0;\n",
    "    // Reductions for addition.\n",
    "    #pragma omp parallel reduction(+:i) num_threads(10)\n",
    "    {\n",
    "        i=1;\n",
    "    }\n",
    "    printf(\"Value if i after parallel region with reduction(+:i) is %d\\n\",i);\n",
    "\n",
    "    // Reductions for max.\n",
    "    #pragma omp parallel reduction(max:i) num_threads(20)\n",
    "    {\n",
    "        i=omp_get_thread_num();\n",
    "    }\n",
    "    printf(\"Value if i after parallel region with reduction(max:i) is %d\\n\",i);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/reductions.c -o C/reductions.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value if i prior to parallel region is 99\n",
      "Value if i after parallel region with private(i) is 99\n",
      "Value if i after parallel region with reduction(+:i) is 10\n",
      "Value if i after parallel region with reduction(max:i) is 19\n"
     ]
    }
   ],
   "source": [
    "!C/./reductions.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the above code going to [reductions.c](C/reductions.c). Other reduction operations are:\n",
    "* Multiplication (*)\n",
    "* Minimun (min)\n",
    "* Bitwise AND (&)\n",
    "* Bitwise OR (|)\n",
    "* Bitwise XOR (^)\n",
    "* Logic AND (&&)\n",
    "* Logic OR (&&)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastprivate\n",
    "\n",
    "Finally, there is lastprivate. Later on we will discuss more about loops and how to distribute them across workers. However, lastprivate allows for the value to be the last value in the iteration space. This means, if we have 10 iterations in a for loop, the value for i = 9 will be copied over.\n",
    "\n",
    "This code shows this behavior. Let us ignore for now the `for` construct. We will go back to it later on.\n",
    "\n",
    "```C\n",
    "    int Array[10];\n",
    "    int i, b;\n",
    "\n",
    "    for (i = 0; i < 10; i++) {\n",
    "        Array[i] = i;\n",
    "    }\n",
    "\n",
    "    #pragma omp parallel for lastprivate(b)\n",
    "    for (i = 0; i < 10; i++)\n",
    "    {\n",
    "        b = Array[i];\n",
    "    }\n",
    "    printf(\"b is %d after the parallel region\\n\", b);\n",
    "\n",
    "    return 0;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp C/lastprivate.c -o C/lastprivate.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b is 9 after the parallel region\n"
     ]
    }
   ],
   "source": [
    "!C/./lastprivate.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with this code going to [lastprivate.c](C/lastprivate.c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Create a program that:\n",
    "1. Initializes an array of 100 elements to random numbers by assigning a thread per element of the array. \n",
    "2. Finds the max value of the array. \n",
    "3. Finds the min value of the array.\n",
    "4. Finds the average value of the array.\n",
    "\n",
    "Go to [exercise2.c](Exercises/exercise2.c) and use the code region below to build and execute your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thread 1: value 7844 in index 9\n",
      " Thread 1: value 3452 in index 10\n",
      " Thread 1: value 5633 in index 11\n",
      " Thread 1: value 8945 in index 12\n",
      " Thread 1: value 4145 in index 13\n",
      " Thread 1: value 6292 in index 14\n",
      " Thread 1: value 5451 in index 15\n",
      " Thread 1: value 2576 in index 16\n",
      " Thread 1: value 3463 in index 17\n",
      " Thread 0: value 6475 in index 0\n",
      " Thread 0: value 6291 in index 1\n",
      " Thread 0: value 2343 in index 2\n",
      " Thread 0: value 4749 in index 3\n",
      " Thread 0: value 692 in index 4\n",
      " Thread 0: value 659 in index 5\n",
      " Thread 0: value 154 in index 6\n",
      " Thread 0: value 8431 in index 7\n",
      " Thread 0: value 818 in index 8\n",
      " Thread 11: value 1679 in index 92\n",
      " Thread 11: value 1482 in index 93\n",
      " Thread 11: value 7246 in index 94\n",
      " Thread 11: value 3962 in index 95\n",
      " Thread 11: value 9896 in index 96\n",
      " Thread 11: value 2480 in index 97\n",
      " Thread 11: value 8238 in index 98\n",
      " Thread 11: value 8409 in index 99\n",
      " Thread 9: value 4101 in index 76\n",
      " Thread 9: value 7404 in index 77\n",
      " Thread 9: value 5413 in index 78\n",
      " Thread 9: value 8487 in index 79\n",
      " Thread 9: value 2836 in index 80\n",
      " Thread 9: value 4610 in index 81\n",
      " Thread 9: value 5413 in index 82\n",
      " Thread 9: value 689 in index 83\n",
      " Thread 8: value 3287 in index 68\n",
      " Thread 8: value 4817 in index 69\n",
      " Thread 8: value 1780 in index 70\n",
      " Thread 8: value 8017 in index 71\n",
      " Thread 8: value 1017 in index 72\n",
      " Thread 8: value 2970 in index 73\n",
      " Thread 8: value 6817 in index 74\n",
      " Thread 8: value 9158 in index 75\n",
      " Thread 4: value 5919 in index 36\n",
      " Thread 4: value 1162 in index 37\n",
      " Thread 4: value 5736 in index 38\n",
      " Thread 4: value 8814 in index 39\n",
      " Thread 4: value 4331 in index 40\n",
      " Thread 4: value 4431 in index 41\n",
      " Thread 4: value 579 in index 42\n",
      " Thread 4: value 2819 in index 43\n",
      " Thread 5: value 1325 in index 44\n",
      " Thread 5: value 3159 in index 45\n",
      " Thread 5: value 1888 in index 46\n",
      " Thread 5: value 8127 in index 47\n",
      " Thread 5: value 5581 in index 48\n",
      " Thread 2: value 6237 in index 18\n",
      " Thread 2: value 1670 in index 19\n",
      " Thread 3: value 8468 in index 27\n",
      " Thread 3: value 4500 in index 28\n",
      " Thread 7: value 6091 in index 60\n",
      " Thread 5: value 4633 in index 49\n",
      " Thread 5: value 1983 in index 50\n",
      " Thread 2: value 8053 in index 20\n",
      " Thread 2: value 5669 in index 21\n",
      " Thread 2: value 1479 in index 22\n",
      " Thread 2: value 7226 in index 23\n",
      " Thread 2: value 643 in index 24\n",
      " Thread 2: value 5207 in index 25\n",
      " Thread 2: value 7712 in index 26\n",
      " Thread 10: value 3436 in index 84\n",
      " Thread 10: value 6392 in index 85\n",
      " Thread 5: value 2043 in index 51\n",
      " Thread 6: value 2784 in index 52\n",
      " Thread 6: value 55 in index 53\n",
      " Thread 6: value 5132 in index 54\n",
      " Thread 6: value 8746 in index 55\n",
      " Thread 6: value 8047 in index 56\n",
      " Thread 6: value 3145 in index 57\n",
      " Thread 6: value 4719 in index 58\n",
      " Thread 6: value 5844 in index 59\n",
      " Thread 7: value 2816 in index 61\n",
      " Thread 7: value 9707 in index 62\n",
      " Thread 7: value 2324 in index 63\n",
      " Thread 7: value 5405 in index 64\n",
      " Thread 7: value 7739 in index 65\n",
      " Thread 7: value 3807 in index 66\n",
      " Thread 10: value 3856 in index 86\n",
      " Thread 10: value 9727 in index 87\n",
      " Thread 10: value 9128 in index 88\n",
      " Thread 10: value 5911 in index 89\n",
      " Thread 10: value 2467 in index 90\n",
      " Thread 10: value 7298 in index 91\n",
      " Thread 3: value 1342 in index 29\n",
      " Thread 3: value 3432 in index 30\n",
      " Thread 3: value 9759 in index 31\n",
      " Thread 3: value 2918 in index 32\n",
      " Thread 3: value 1506 in index 33\n",
      " Thread 3: value 1190 in index 34\n",
      " Thread 3: value 2448 in index 35\n",
      " Thread 7: value 2652 in index 67\n",
      "------------- END parallel zone-----------\n",
      "Max is 9896,\n",
      "Min is 55,\n",
      "Average is 4678.38\n",
      "Real Max is 9896,\n",
      "Real Min is 55,\n",
      "Real Average is 4678.38\n"
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp Exercises/exercise2.c -o Exercises/exercise2.exe && Exercises/./exercise2.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
